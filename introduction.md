# 介绍
`Apache``Kafka`®是一个分布式流平台。这到底是什么意思呢？
流平台具有三个关键功能：

- 发布和订阅记录流，类似于消息队列或企业消息传递系统。
- 以容错的持久方式存储记录流。
- 处理记录流。

`Kafka`通常用于两大类应用程序：

- 建立实时流数据管道，以可靠地在系统或应用程序之间获取数据
- 构建实时流应用程序，以转换或响应数据流

要了解`Kafka`如何执行这些操作，让我们从头开始深入研究`Kafka`的功能。

首先几个概念：

- `Kafka`在一个或多个可以跨越多个数据中心的服务器上作为集群运行。
- `Kafka`集群将记录流存储在称为`topic`的类别中。
- 每个记录由一个键，一个值和一个时间戳组成。

`Kafka`具有四个核心`API`：

- [生产者`API`](https://kafka.apache.org/documentation.html#producerapi)允许应用程序发布的记录流至一个或多个`Kafaka`的`topic`。
- [消费者`API`](https://kafka.apache.org/documentation.html#consumerapi)允许应用程序订阅一个或多个`topic`，并处理所产生的对他们记录的数据流。
- [流`API`](https://kafka.apache.org/documentation/streams/)允许应用程序充当流处理器，从一个或多个`topic`消费的输入流，并产生一个输出流至一个或多个输出的`topic`，有效地将输入数据流转换成输出流。
- [连接器`API`](https://kafka.apache.org/documentation.html#connect)允许构建和运行可重复使用的生产者或消费者连接`kafaka``topic`到现有的应用程序或数据系统。例如，关系数据库的连接器可能会捕获对表的所有更改。

![](images/kafka-apis.png)

在`Kafka`中，客户端和服务器之间的通信是通过简单，高性能，与语言无关的`TCP`协议完成的。该协议已版本化，并与旧版本保持向后兼容性。我们为`Kafka`提供了`Java`客户端，但是客户端支持[多种语言](https://cwiki.apache.org/confluence/display/KAFKA/Clients)。

## Topic和日志
首先，让我们深入探讨`Kafka`提供的记录`topic`的核心抽象。

`topic`是将记录发布到的类别或订阅源名称。`Kafka`中的`topic`始终是多用户的；也就是说，一个`topic`可以有零个，一个或多个消费者来订阅写入该`topic`的数据。

对于每个`topic`，`Kafka`集群都会维护一个分区日志，如下所示：

![](images/log_anatomy.png)

每个分区都是有序的，不变的记录序列，这些记录连续地附加到结构化的提交日志中。分别为分区中的记录分配了一个顺序`ID`号，称为`offset`，该`ID`号唯一标识分区中的每个记录。

`Kafka`集群使用可配置的保留期限持久保留所有已发布的记录（无论是否已使用它们）。例如，如果将保留策略设置为两天，则在发布记录后的两天内，该记录可供使用，之后将被丢弃以释放空间。`Kafka`的性能相对于数据大小实际上是恒定的，因此长时间存储数据不是问题。

![](images/log_anatomy.png)

实际上，基于每个消费者保留的唯一元数据是该消费者在日志中的偏移量或位置。此偏移量由消费者控制：通常，消费者在读取记录时会线性地推进其偏移量，但是实际上，由于位置是由消费者控制的，因此它可以按喜欢的任何顺序使用记录。例如，消费者可以重置到较旧的偏移量以重新处理过去的数据，或者跳到最近的记录并从“现在”开始使用。

这些功能的组合意味着`Kafka`的消费者非常`cheap`-他们来来去去对集群或其他消费者没有太大影响。例如，您可以使用我们的命令行工具来“尾部”任何`topic`的内容，而无需更改任何现有消费者所消耗的内容。

日志中的分区有多种用途。首先，它们允许日志扩展到超出单个服务器所能容纳的大小。每个单独的分区都必须适合承载它的服务器，但是一个`topic`可能有很多分区，因此它可以处理任意数量的数据。其次，它们充当并行性的单元-稍有更多。

## 分布
日志的分区分布在`Kafka`群集中的服务器上，每台服务器处理数据并要求共享分区。每个分区都跨可配置数量的服务器复制，以实现容错功能。

每个分区都有一个充当"leader"的服务器和零个或多个充当"followers"的服务器。领导者处理对分区的所有读写请求，而跟随者则被动地复制领导者。如果领导者失败，则跟随者之一将自动成为新领导者。每个服务器充当其某些分区的领导者，而充当其他分区的跟随者，因此群集是负载均衡的。

## 地理复制
`Kafka` `MirrorMaker`为您的集群提供地理复制支持。使用`MirrorMaker`，可以在多个数据中心或云区域中复制消息。您可以在主动/被动方案中使用它进行备份和恢复。或在主动/主动方案中将数据放置在离您的用户更近的位置，或支持数据位置要求。

## 生产者
生产者将数据发布到他们选择的`topic`。生产者负责选择将哪个记录分配给`topic`中的哪个分区。可以以循环方式完成此操作，仅是为了平衡负载，也可以根据某些语义分区功能（例如基于记录中的某些键）进行此操作。一秒钟就可以了解更多有关分区的信息！

## 消费者
消费者使用消费者组名称标记自己，并且发布到`topic`的每条记录都会传递到每个订阅消费者组中的一个消费者实例。消费者实例可以在单独的进程中或在单独的机器上。

如果所有消费者实例都具有相同的消费者组，那么将在这些消费者实例上有效地平衡记录。

如果所有消费者实例具有不同的消费者组，则每个记录将广播到所有消费者进程。

![](images/consumer-groups.png)

由两台服务器组成的`Kafka`群集，其中包含四个带有两个消费者组的分区（`P0-P3`）。消费者组`A`有两个消费者实例，组`B`有四个。

但是，更常见的是，我们发现`topic`具有少量的消费者组，每个“逻辑订户”一个。每个组均由许多消费者实例组成，以实现可伸缩性和容错能力。这无非就是发布-订阅语义，其中订阅者是消费者的集群而不是单个进程。

在`Kafka`中实现使用的方式是通过在使用方实例上划分日志中的分区，以便每个实例在任何时间点都是分区“公平份额”的排他使用方。`Kafka`协议动态处理了维护组成员身份的过程。如果新实例加入该组，它们将接管该组其他成员的某些分区；如果实例死亡，则其分区将分配给其余实例。

`Kafaka`只提供了记录的总订单中的一个分区，而不是一个`topic`的不同分区之间。对于大多数应用程序，按分区排序以及按键对数据进行分区的能力就足够了。但是，如果您需要记录的总订单量，则可以使用只有一个分区的`topic`来实现，尽管这将意味着每个消费者组只有一个消费者。

## 多租户
您可以将`Kafka`部署为多租户解决方案。通过配置哪些`topic`可以产生或使用数据来启用多租户。配额也有运营支持。管理员可以在请求上定义和实施配额，以控制客户端使用的代理资源。有关更多信息，请参阅[安全性文档](https://kafka.apache.org/documentation/#security)。

## 保证
在较高级别上，`Kafka`提供以下保证：

- 生产者发送到特定`topic`分区的消息将按其发送顺序附加。也就是说，如果记录`M1`由与记录`M2`相同的生产者发送，并且首先发送`M1`，则`M1`的偏移量将小于`M2`，并在日志中更早出现。
- 消费者实例按记录在日志中的存储顺序查看记录。
- 对于具有复制因子`N`的`topic`，我们最多可以容忍`N-1`个服务器故障，而不会丢失任何提交给日志的记录。

在文档的设计部分中提供了有关这些保证的更多详细信息。

## `Kafka`作为消息传递系统
`Kafka`的流概念与传统的企业消息传递系统相比如何？

传统上，消息传递具有两种模型：队列和发布-订阅。在队列中，一组消费者可以从服务器中读取内容，并且每条记录都将转到其中一个。在发布-订阅记录中广播给所有消费者。这两个模型中的每一个都有优点和缺点。队列的优势在于，它允许您将数据处理划分到多个消费者实例上，从而扩展处理量。不幸的是，队列不是多用户的—一次进程读取了丢失的数据。发布-订阅允许您将数据广播到多个进程，但是由于每条消息都传递给每个订阅者，因此无法扩展处理。

`Kafaka`的消费者群体概念概括了这两个概念。与队列一样，消费者组允许您将处理划分为一组进程（消费者组的成员）。与发布订阅一样，`Kafka`允许您将消息广播到多个消费者组。

`Kafka`模型的优势在于，每个`topic`都具有这两个属性-可以扩展处理范围，并且是多订阅者-无需选择其中一个。

与传统的消息传递系统相比，`Kafka`还具有更强的订购保证。

传统队列将记录按顺序保留在服务器上，如果有多个消费者从队列中消费，则服务器将按记录的存储顺序分发记录。但是，尽管服务器按顺序分发记录，但是这些记录是异步传递给消费者的，因此它们可能在不同的消费者上乱序到达。这实际上意味着在并行使用的情况下会丢失记录的顺序。消息传递系统通常通过“专有消费者”的概念来解决此问题，该概念仅允许一个进程从队列中使用，但是，这当然意味着在处理中没有并行性。

`Kafaka`做得更好。通过在`topic`内具有并行性（即分区）的概念，Kafka能够在用户进程池中提供排序保证和负载均衡。这是通过将`topic`中的分区分配给消费者组中的消费者来实现的，以便每个分区都由组中的一个消费者完全消费。通过这样做，我们确保消费者是该分区的唯一读取器，并按顺序使用数据。由于存在许多分区，因此仍然可以平衡许多消费者实例上的负载。但是请注意，消费者组中的消费者实例不能超过分区。

## `Kafka`作为存储系统
任何允许发布与使用无关的消息发布的消息队列都有效地充当了运行中消息的存储系统。`Kafka`的不同之处在于它是一个非常好的存储系统。

写入`Kafka`的数据将写入磁盘并进行复制以实现容错功能。`Kafka`允许生产者等待确认，以便直到完全复制并确保即使写入服务器失败的情况下写入也不会完成。

`Kafka`的磁盘结构可以很好地扩展使用-无论服务器上有`50KB`还是`50TB`的持久数据，`Kafka`都将执行相同的操作。

认真对待存储并允许客户端控制其读取位置的结果是，您可以将`Kafka`视为一种专用于高性能，低延迟提交日志存储，复制和传播的专用分布式文件系统。

有关`Kafka`的提交日志存储和复制设计的详细信息，请阅读[此页面](https://kafka.apache.org/documentation/#design)。

## `Kafka`用于流处理
仅读取，写入和存储数据流是不够的，目的是实现对流的实时处理。

在`Kafka`中，流处理器是指从输入`topic`中获取连续数据流，对该输入进行一些处理并生成连续数据流以输出`topic`的任何东西。

例如，零售应用程序可以接受销售和装运的输入流，并输出根据此数据计算出的重新订购和价格调整流。

可以直接使用生产者和消费者`API`进行简单处理。但是，对于更复杂的转换，`Kafka`提供了完全集成的`Streams API`。这允许构建执行非重要处理的应用程序，这些应用程序计算流的聚合或将流连接在一起。

该功能有助于解决此类应用程序所面临的难题：处理无序数据，在代码更改时重新处理输入，执行状态计算等。

流`API`建立在`Kafka`提供的核心原语之上：它使用生产者和消费者`API`进行输入，使用`Kafka`进行状态存储，并使用相同的组机制来实现流处理器实例之间的容错。

## 拼凑在一起
消息，存储和流处理的这种组合看似不寻常，但这对于`Kafka`作为流平台的角色至关重要。

像`HDFS`这样的分布式文件系统允许存储静态文件以进行批处理。实际上，像这样的系统可以存储和处理过去的历史数据。

传统的企业消息传递系统允许处理将来的消息，这些消息将在您订阅后到达。以这种方式构建的应用程序会在将来的数据到达时对其进行处理。

`Kafka`结合了这两种功能，对于将`Kafka`用作流应用程序平台和流数据管道平台而言，这种结合至关重要。

通过结合存储和低延迟订阅，流应用程序可以以相同的方式处理过去和将来的数据。那是一个单一的应用程序可以处理历史数据，存储的数据，而不是在到达最后一条记录时结束，而是可以在将来的数据到达时继续进行处理。这是流处理的通用概念，它包含批处理以及消息驱动的应用程序。

同样，对于流数据管道，对实时事件的订阅组合使得可以将`Kafka`用于非常低延迟的管道。但是可靠地存储数据的能力使得可以将其用于必须保证数据传输的关键数据，或与仅定期加载数据或可能停机很长时间进行维护的脱机系统集成。流处理设施使得可以在数据到达时对其进行转换。

有关`Kafka`提供的担保，`API`和功能的更多信息，请参阅[本文档](https://kafka.apache.org/documentation.html)的其余部分。