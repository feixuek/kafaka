# 5. 实现

## 5.1 网络层
网络层是一个相当简单的`NIO`服务器，因此将不对其进行详细描述。`sendfile`实现是通过为`MessageSet`接口提供`writeTo`方法来完成的。这允许文件支持的消息集使用更有效的`transferTo`实现，而不是进程内缓冲的写操作。线程模型是一个接收线程和`N`个处理器线程，每个线程处理固定数量的连接。该设计已经在其他地方进行了全面的测试，发现易于实现且速度很快。该协议保持非常简单，以允许将来以其他语言实现客户端。

## 5.2 消息
消息由可变长度的头部，可变长度的不透明键字节数组和可变长度的不透明值字节数组组成。标头的格式在下一节中描述。保留键和值不透明是正确的决定：序列化库目前正在取得很大进展，并且任何特定的选择不太可能适合所有用途。不用说，使用`Kafka`的特定应用程序可能会强制要求特定的序列化类型作为其使用的一部分。该`RecordBatch`接口只是一个消息迭代器，它具有用于批量读取和写入`NIO`的专用方法`Channel`。

## 5.3 消息格式
消息（也称为记录）始终成批写入。一批消息的技术术语是一个记录批，并且一个记录批包含一个或多个记录。在简并的情况下，我们可以有一个包含单个记录的记录批。记录批和记录具有自己的标题。每个文件的格式如下所述。

### 5.3.1 记录批次
以下是`RecordBatch`的磁盘格式。
```
baseOffset: int64
batchLength: int32
partitionLeaderEpoch: int32
magic: int8 (current magic value is 2)
crc: int32
attributes: int16
    bit 0~2:
        0: no compression
        1: gzip
        2: snappy
        3: lz4
        4: zstd
    bit 3: timestampType
    bit 4: isTransactional (0 means not transactional)
    bit 5: isControlBatch (0 means not a control batch)
    bit 6~15: unused
lastOffsetDelta: int32
firstTimestamp: int64
maxTimestamp: int64
producerId: int64
producerEpoch: int16
baseSequence: int32
records: [Record]
```  
请注意，启用压缩后，紧随记录数量的计数直接对压缩的记录数据进行序列化。

`CRC`覆盖了从属性到批处理末尾的数据（即，`CRC`之后的所有字节）。它位于魔术字节之后，这意味着客户端必须先解析魔术字节，然后再决定如何解释批处理长度和魔术字节之间的字节。分区领导者纪元字段不包括在`CRC`计算中，以避免在为代理收到的每个批次分配此字段时重新计算`CRC`。`CRC-32C（Castagnoli）`多项式用于计算。

关于压缩：与旧的消息格式不同，当清理日志时，`magic v2`及更高版本保留原始批处理中的第一个和最后一个偏移/序列号。为了能够在重新加载日志时恢复生产者的状态，这是必需的。例如，如果我们没有保留最后的序列号，则在分区引导失败后，生产者可能会看到`OutOfSequence`错误。必须保留基本序列号以进行重复检查（代理通过验证传入批处理的第一个和最后一个序列号与该生产者的最后一个序列是否匹配来检查传入的`Produce`请求是否存在重复项）。结果，当清除批次中的所有记录但仍保留批次以保留生产者的最后序列号时，日志中可能有空批次。

#### 5.3.1.1 控制批次
一个控制批包含一个称为控制记录的记录。控制记录不应传递给应用程序。取而代之的是，消费者使用它们来过滤掉中止的事务消息。

控制记录的键符合以下架构：
```
version: int16 (current version is 0)
type: int16 (0 indicates an abort marker, 1 indicates a commit)
```
控制记录的值的模式取决于类型。该值对客户端不透明。

### 5.3.2 记录
记录级别标题是在`Kafka 0.11.0`中引入的。带有标题的记录的磁盘格式如下。

```
length: varint
attributes: int8
    bit 0~7: unused
timestampDelta: varint
offsetDelta: varint
keyLength: varint
key: byte[]
valueLen: varint
value: byte[]
Headers => [Header]
```   

#### 5.3.2.1 记录标题
```
headerKeyLength: varint
headerKey: String
headerValueLength: varint
Value: byte[]
```     
我们使用与`Protobuf`相同的`varint`编码。关于后者的更多信息可以在这里找到。记录中的标头计数也被编码为`varint`。

### 5.3.3 旧消息格式
在`Kafka 0.11`之前，已传输消息并将其存储在消息集中。在消息集中，每个消息都有其自己的元数据。请注意，尽管消息集被表示为一个数组，但它们没有像协议中的其他数组元素一样以int32数组大小开头。

消息集合：
```
MessageSet (Version: 0) => [offset message_size message]
    offset => INT64
    message_size => INT32
    message => crc magic_byte attributes key value
        crc => INT32
        magic_byte => INT8
        attributes => INT8
            bit 0~2:
                0: no compression
                1: gzip
                2: snappy
            bit 3~7: unused
        key => BYTES
        value => BYTES
MessageSet (Version: 1) => [offset message_size message]
    offset => INT64
    message_size => INT32
    message => crc magic_byte attributes key value
        crc => INT32
        magic_byte => INT8
        attributes => INT8
            bit 0~2:
                0: no compression
                1: gzip
                2: snappy
                3: lz4
            bit 3: timestampType
                0: create time
                1: log append time
            bit 4~7: unused
        timestamp =>INT64
        key => BYTES
        value => BYTES
```
在`Kafka 0.10`之前的版本中，唯一受支持的消息格式版本（在`magic`值中指示）为0。在版本`0.10`中引入了带有时间戳支持的消息格式版本1。

- 与上述版本2相似，属性的最低位表示压缩类型。
- 在版本1中，生产者应始终将时间戳记类型位设置为0。如果将主题配置为使用日志追加时间，（通过代理级别的配置`log.message.timestamp.type=LogAppendTime`或主题级别的配置`message.timestamp.type=LogAppendTime`），代理将覆盖时间戳记类型和消息集中的时间戳记。
- 属性的最高位必须设置为0。

在消息格式版本0和1中，`Kafka`支持递归消息以启用压缩。在这种情况下，必须设置消息的属性以指示其中一种压缩类型，并且`value`字段将包含使用该类型压缩的消息集。我们通常将嵌套消息称为“内部消息”，将包装消息称为“外部消息”。请注意，对于外部消息，键应为`null`，其偏移量将是最后一个内部消息的偏移量。

当接收到递归版本0消息时，代理将它们解压缩，并且每个内部消息将分别分配一个偏移量。在版本1中，为避免服务器端重新压缩，仅将包装消息分配一个偏移量。内部消息将具有相对偏移量。可以使用与外部消息的偏移来计算绝对偏移，该偏移对应于分配给最后一个内部消息的偏移。

`crc`字段包含后续消息字节（即从魔术字节到值）的`CRC32`（而不是`CRC-32C`）。

## 5.4 日志
具有两个分区的名为"my_topic"的主题的日志由两个目录（即`my_topic_0`和`my_topic_1`）组成，该目录中填充有包含该主题的消息的数据文件。日志文件的格式是“日志条目”的序列；每个日志条目是一个4字节整数`N`，用于存储消息长度，后跟N个消息字节。每条消息均由64位整数偏移量唯一标识给出该消息开始在该分区上发送给该主题的所有消息流中的字节位置。每个消息的磁盘格式如下。每个日志文件都以其包含的第一条消息的偏移量命名。因此，创建的第一个文件将是`00000000000.kafka`，每个其他文件将具有一个整数名称，该整数名称比前一个文件大约S个字节，其中S是配置中给定的最大日志文件大小。

记录的确切二进制格式被版本化并维护为标准接口，因此可以在生产者，经纪人和客户之间转移记录批次，而无需在需要时进行重新复制或转换。上一节包括有关记录的磁盘格式的详细信息。

使用消息偏移量作为消息ID是不常见的。我们最初的想法是使用生产者生成的GUID，并维护从GUID到每个代理的偏移量的映射。但是，由于使用者必须为每个服务器维护一个ID，因此GUID的全局唯一性没有任何价值。此外，维护从随机id到偏移量的映射的复杂性要求必须与磁盘同步的较重的索引结构，本质上需要完整的持久性随机访问数据结构。因此，为了简化查找​​结构，我们决定使用一个简单的按分区原子计数器，该计数器可以与分区ID和节点ID结合使用，以唯一地标识一条消息。尽管每个消费者请求仍有可能进行多次搜索，但这使查找结构更简单。但是，一旦我们在柜台上定居，跳转到直接使用偏移量似乎很自然-毕竟都是分区唯一的单调递增整数。由于偏移量是从消费者API中隐藏的，因此该决定最终是实现细节，因此我们采用了更有效的方法。

![](../images/kafka_log.png)

### 写
该日志允许串行追加，该追加始终会转到最后一个文件。当该文件达到可配置的大小（例如1GB）时，它将被滚动到一个新文件中。日志采用两个配置参数：M，它给出强制操作系统将文件刷新到磁盘之前要写入的消息数，而S则给出强制刷新的秒数。这样可以持久保证在系统崩溃时最多丢失M条消息或S秒的数据。

### 读
通过给出消息的64位逻辑偏移和S字节最大块大小来完成读取。这将对包含在S字节缓冲区中的消息返回一个迭代器。S旨在大于任何单个消息，但是如果消息异常大，则可以多次重试读取，每次将缓冲区大小加倍，直到成功读取消息为止。可以指定最大消息和缓冲区大小，以使服务器拒绝大于某个大小的消息，并为客户机绑定以获得完整消息所需的最大读取大小。读缓冲区很可能以部分消息结尾，这很容易通过大小限制来检测。

从偏移量读取的实际过程需要首先找到存储数据的日志段文件，然后从全局偏移量值计算特定于文件的偏移量，然后从该文件偏移量进行读取。搜索是针对每个文件所维护的内存范围的简单二进制搜索变体。

该日志提供了获取最新写入的消息的功能，以允许客户端从“立即”开始订阅。如果使用者在其SLA指定的天数内无法使用其数据，这也很有用。在这种情况下，当客户端尝试使用不存在的偏移量时，将为其提供`OutOfRangeException`异常，并且可以重置自身，也可以根据使用情况进行故障处理。

以下是发送给使用者的结果格式。

```
MessageSetSend (fetch result)
 
total length     : 4 bytes
error code       : 2 bytes
message 1        : x bytes
...
message n        : x bytes

MultiMessageSetSend (multiFetch result)
 
total length       : 4 bytes
error code         : 2 bytes
messageSetSend 1
...
messageSetSend n
```

### 删除
一次删除一个日志段的数据。日志管理器允许可插入的删除策略选择哪些文件可以删除。尽管保留最后`N GB`的策略也可能有用，但当前策略会删除修改时间超过N天的任何日志。为了避免锁定读取同时仍允许删除修改段列表的情况，我们使用写时复制样式段列表实现，该实现提供一致的视图，以允许在删除进行中在日志段的不可变静态快照视图上进行二进制搜索。

### 保证
该日志提供配置参数M，该参数控制在强制刷新到磁盘之前写入的最大消息数。启动时，将运行日志恢复过程，该过程将遍历最新日志段中的所有消息并验证每个消息条目是否有效。如果消息条目的大小和偏移量之和小于文件的长度，并且消息有效负载的CRC32与消息存储的CRC匹配，则该消息条目有效。如果检测到损坏，日志将被截断为最后一个有效偏移量。

请注意，必须处理两种损坏：截断（其中由于崩溃而丢失未写入的块）和损坏（其中将无用的块添加到文件中）。这样做的原因是，通常情况下，操作系统无法保证文件inode和实际块数据之间的写入顺序，因此，如果丢失inode并以新的大小进行更新，则除了丢失写入的数据外，文件还可以获得无用的数据。在写入包含该数据的块之前发生崩溃。CRC检测到这种极端情况，并防止它破坏日志（尽管未写消息当然会丢失）。

## 5.5 发行
### 消费者抵销追踪
`Kafka`使用者跟踪其在每个分区中消耗的最大偏移量，并且能够提交偏移量，以便在重新启动时可以从这些偏移量中恢复。`Kafka`提供了一个选项，可以将给定消费者组的所有抵销存储在一个称为组协调器的指定经纪人（针对该组）中。也就是说，该消费者组中的任何消费者实例都应将其偏移量提交和获取发送到该组协调器（经纪人）。消费者组根据其组名分配给协调员。消费者可以通过向任何`Kafka`代理发出`FindCoordinatorRequest`并读取包含协调器详细信息的`FindCoordinatorResponse`来查找其协调器。消费者然后可以继续从协调代理处提交或获取偏移。万一协调员移动，消费者将需要重新发现协调员。偏移提交可以自动或由使用者实例手动完成。

当组协调器收到`OffsetCommitRequest`时，它将请求附加到一个名为`__consumer_offset`s的特殊压缩的 `Kafka`主题。仅在偏移量主题的所有副本都接收到偏移量后，代理程序才会向使用者发送成功的偏移量提交响应。如果偏移量无法在可配置的超时时间内复制，则偏移量提交将失败，使用方可以在回退后重试该提交。代理定期压缩偏移量主题，因为它只需要维护每个分区的最新偏移量提交。协调器还将偏移量缓存在内存表中，以便快速处理偏移量获取。

当协调器收到偏移量获取请求时，它仅从偏移量缓存中返回最后提交的偏移量向量。如果协调程序刚刚启动，或者如果它刚刚成为一组新的消费者组的协调程序（通过成为偏移量主题分区的领导者），则可能需要将偏移量主题分区加载到缓存中。在这种情况下，偏移量获取将失败，并出现`CoordinatorLoadInProgressException`，并且使用者可以在回退后重试`OffsetFetchRequest`。

### ZooKeeper目录
下面给出了`ZooKeeper`的结构和算法，用于消费者和经纪人之间的协调。

### 符号
当路径中的元素表示为`[xyz]`时，这意味着`xyz`的值不是固定的，实际上每个`xyz`的可能值都有一个`ZooKeeper znode`。例如，`/topics/[topic]`将是一个名为`/topics`的目录，其中包含每个主题名称的子目录。还给出了数字范围，例如`[0 ... 5]`以指示子目录`0、1、2、3、4`。箭头`->`用于指示`znode`的内容。例如，`/hello->world`将指示`znode/hello`包含值`world`。

### 代理节点注册表
```
/brokers/ids/[0...N] --> {"jmx_port":...,"timestamp":...,"endpoints":[...],"host":...,"version":...,"port":...} (ephemeral node)
```
这是所有现有代理节点的列表，每个代理节点都提供一个唯一的逻辑代理`ID`，以将其标识给使用者（必须将其作为配置的一部分提供）。启动时，代理节点通过在`/brokers/ids`下创建一个逻辑代理`id`为`znode`来注册自己。逻辑代理程序ID的目的是允许将代理程序移动到其他物理计算机而不会影响使用者。尝试注册已经使用的代理`ID`（例如，因为两个服务器配置了相同的代理`ID`）会导致错误。

由于代理使用短暂的`znode`在`ZooKeeper`中进行注册，因此该注册是动态的，并且在代理关闭或死亡时将消失（从而通知消费者不再可用）。

### 经纪人主题注册
```
/brokers/topics/[topic]/partitions/[0...N]/state --> {"controller_epoch":...,"leader":...,"version":...,"leader_epoch":...,"isr":[...]} (ephemeral node)
```
每个代理在其维护的主题下进行注册，并存储该主题的分区数。

## 集群ID
集群`ID`是分配给`Kafka`集群的唯一且不变的标识符。群集ID最多可以包含22个字符，并且允许的字符由正则表达式`[a-zA-Z0-9 _ \-] +`定义，该正则表达式对应于`URL`安全的`Base64`变体使用的字符，不带填充。从概念上讲，它是在首次启动集群时自动生成的。

在实现方面，它是在首次成功启动具有`0.10.1`或更高版本的代理时生成的。代理`/cluster/id`在启动期间尝试从`znode`获取群集`ID` 。如果`znode`不存在，则代理将生成一个新的集群`ID`，并使用该集群`ID`创建`znode`。

### 经纪人节点注册
代理节点基本上是独立的，因此它们仅发布有关其拥有的信息。代理加入后，它将在代理节点注册表目录下注册自己，并写入有关其主机名和端口的信息。代理还将在代理主题注册表中注册现有主题及其逻辑分区的列表。在代理上创建新主题时，它们会动态注册。